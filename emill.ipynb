{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "emill.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMHOk7z3uivox/awr2qbZ61",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/crerarc/DataScience/blob/main/emill.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crBb5tBEMNjN"
      },
      "source": [
        "# Best stab at picking Lottery numbers\n",
        "\n",
        "C. Christie, 01/02/2022\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Module Imports\n",
        "\n",
        "# Import libraries\n",
        "import random\n",
        "import datetime as dt\n",
        "import itertools as itr\n",
        "import os\n",
        "from numpy import select as npselect\n",
        "import pandas as pd\n",
        "from google.colab import drive # Google file access"
      ],
      "metadata": {
        "id": "ul_5s-7-h6tR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title MAIN SEQUENCE\n",
        "def main() -> None:\n",
        "    \"\"\"Main run sequence\n",
        "    \"\"\"\n",
        "\n",
        "    # Data file\n",
        "    drive = \"gdrive/My Drive/Colab Notebooks/Data/\"\n",
        "    #ifile = \"/mnt/Disk01/DataA/ProjectsA/python_workspace/EuroMilLot/\"\n",
        "    #ifile = \"/home/crerar/DataA/ProjectsA/python_workspace/EuroMilLot/\"\n",
        "\n",
        "    # Get data\n",
        "    df5, df2 = get_data(drive)\n",
        "\n",
        "    # Df setup to record results\n",
        "    dfr = pd.DataFrame(columns = ['GB1','GB2','GB3','GB4','GB5','GS1','GS2',\n",
        "        'W1', 'W2', 'W3', 'W4', 'W5', 'W6', 'W7', 'W8', 'W9', 'W10', 'W11', 'W12', 'W13', ])\n",
        "    \n",
        "    # Try\n",
        "    try5 = [10, 11, 13, 35, 41]\n",
        "    try2 = [6, 8]\n",
        "\n",
        "    # Check guess\n",
        "    wins = get_guess(df5, df2, try5, try2)\n",
        "    print(wins)\n",
        "    print(f\"Win frequency: {round(100* sum(wins.values())/ len(df5), 2)}%\")\n",
        "\n",
        "\n",
        "    return 0 # Return successful completion = zero errors, or errors = False"
      ],
      "metadata": {
        "id": "VqxPqakwiT8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Function: \"get_data\" - Reads draw results and update repository as reqd\n",
        "def get_data(rt_dir: str) -> tuple:\n",
        "    \"\"\"[summary]\n",
        "\n",
        "    Args:\n",
        "        ifile (str): input repository directory\n",
        "\n",
        "    Returns:\n",
        "        tuple: df1, df2 - dataframes for 5 main balls and 2 star balls respectively\n",
        "    \"\"\"\n",
        "\n",
        "    # COLLAB for user repository file\n",
        "    # ...Check path open\n",
        "    if not(os.path.ismount(\"/content/gdrive\")):\n",
        "        drive.mount(\"/content/gdrive\")\n",
        "    #print(os.listdir())\n",
        "\n",
        "    # LOCAL for user repository file\n",
        "    rfile = 'https://www.national-lottery.co.uk/results/euromillions/draw-history/csv'\n",
        "\n",
        "    # Create parser to parse date variables\n",
        "    my_parser = lambda csv_date: dt.datetime.strptime(csv_date, \"%d-%b-%Y\")\n",
        "\n",
        "    # Read in historic draws csv as a datafile with parsed date as index\n",
        "    src_file = rt_dir + \"euroLotData.csv\"\n",
        "    df_draws_repo = pd.read_csv(src_file, parse_dates = ['DrawDate'],\n",
        "                                date_parser = my_parser,\n",
        "                                index_col = 0).fillna(value = 0)\n",
        "    #print(df_draws_repo.head())\n",
        "\n",
        "    # Read in latest draw table csv, with parsed date as index\n",
        "    df_draws_ltst = pd.read_csv(rfile, parse_dates= ['DrawDate'],\n",
        "                                date_parser = my_parser,\n",
        "                                index_col = 0).fillna(value = 0)\n",
        "    #print(df_draws_ltst.head())\n",
        "\n",
        "    # Get first entry in repository, and check timestamp\n",
        "    repo_last = df_draws_repo.index[0]\n",
        "    ltst_last = df_draws_ltst.index[0]\n",
        "    if ltst_last > repo_last:\n",
        "        # Create a dataframe of missing values, aligned with repository\n",
        "        print(\"! Repo out of date !\")\n",
        "        print(f\"Last Repo: {repo_last.day}, {repo_last.month}, {repo_last.year}\")\n",
        "        print(f\"Last Draw: {ltst_last.day}, {ltst_last.month}, {ltst_last.year}\")\n",
        "        print(\"! Appending !\")\n",
        "        df_2mrg = df_draws_ltst.loc[df_draws_ltst.index > repo_last, :'Lucky Star 2']\n",
        "        df_2mrg.columns = ['B1', 'B2', 'B3', 'B4', 'B5', 'S1', 'S2']\n",
        "        # Concatenate existing repo with missing data to move missing to top\n",
        "        df_drws = pd.concat([df_2mrg, df_draws_repo])\n",
        "        # Create a new file for the data\n",
        "        tst_fil = \"test_out.csv\"\n",
        "        df_drws.to_csv(tst_fil, date_format=\"%d-%b-%Y\")\n",
        "        # Provision to prevent over-write of original file \n",
        "        !mv \"test_out.csv\" \"gdrive/My Drive/Colab Notebooks/Data/euroLotData.csv\"\n",
        "        # mvfile = 'mv ' + ifile + 'test_out.csv ' + lfile\n",
        "        # print(mvfile)\n",
        "        # os.system(mvfile)\n",
        "    else:\n",
        "        print(\"No change to Repository Required\")\n",
        "        df_drws = df_draws_repo.copy()\n",
        "\n",
        "    # Split data frame for 5 draw and 2 draw parts and sum the outcomes\n",
        "    df1 = df_drws.iloc[:,:-2].astype('int')\n",
        "    df1[\"Sum\"] = df1.sum(axis = 1).astype('int')\n",
        "    df2 = df_drws.iloc[:,-2:].astype('int')\n",
        "    df2[\"Sum\"] = df2.sum(axis = 1).astype('int')\n",
        "\n",
        "    return df1, df2\n"
      ],
      "metadata": {
        "id": "dDvfsH6liXl7",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Get a best guess\n",
        "def get_guess(data5: pd.DataFrame, data2: pd.DataFrame,\n",
        "              gues5: list, gues2: list) -> tuple:\n",
        "    \"\"\" Find how successful the chosen guess is\n",
        "        Method: Set intersection to count no in intersection\n",
        "        13 chances to win:\n",
        "        Default no win rank: 14\n",
        "        Idx   5 & 2 Match Rank\n",
        "        [0]     2 + 0       13\n",
        "        [1]     2 + 1       12\n",
        "        [2]     1 + 2       11\n",
        "        [3]     3 + 0       10\n",
        "        [4]     3 + 1       9\n",
        "        [5]     2 + 2       8\n",
        "        [6]     4 + 0       7\n",
        "        [7]     3 + 2       6\n",
        "        [8]     4 + 1       5\n",
        "        [9]     4 + 2       4\n",
        "        [10]    5 + 0       3\n",
        "        [11]    5 + 1       2\n",
        "        [12]    5 + 2       1\n",
        "\n",
        "    Args:\n",
        "        data5 (pd.DataFrame): Frequencies for Draw 5 numbers\n",
        "        data2 (pd.DataFrame): Frequencies for Draw 2 numbers\n",
        "        gues5 (list): Guess for 5 Ball draw\n",
        "        gues2 (list): Guess for 2 Ball draw\n",
        "\n",
        "    Returns:\n",
        "        \n",
        "    \"\"\"\n",
        "\n",
        "    # Create rank dictionary\n",
        "    ranks = {'52':1, '51':2, '50':3, '42':4, '41':5, '32': 6, '40':7,\n",
        "            '22':8, '31':9, '30':10, '12':11, '21':12, '20':13}\n",
        "    \n",
        "    # Create dictionary distribution of wins\n",
        "    win_distrib = {i : 0 for i in range(1, 14)}\n",
        "\n",
        "    for i in range(len(data5)):\n",
        "        # Extract df data as set, i - single row, [[i]] - multiple rows\n",
        "        set5 = set(data5.iloc[i, [0, 1, 2, 3, 4]])\n",
        "        set2 = set(data2.iloc[i, [0, 1]])\n",
        "        # Find all the matching numbers\n",
        "        mtch5 = set5.intersection(set(gues5))\n",
        "        mtch2 = set2.intersection(set(gues2))\n",
        "        res = str(len(mtch5)) + str(len(mtch2))\n",
        "        if res in ranks:\n",
        "            win_distrib[ranks[res]] += 1\n",
        "    \n",
        "    return win_distrib\n"
      ],
      "metadata": {
        "id": "A2qtnydsi7aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Execution Starting Point\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "eBMlhswhjJVK",
        "outputId": "a0849080-cf5e-4cf1-a17b-97e032e9f777"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No change to Repository Required\n",
            "{1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 3, 9: 2, 10: 2, 11: 5, 12: 34, 13: 76}\n",
            "Win frequency: 8.1%\n"
          ]
        }
      ]
    }
  ]
}